spring.application.name=SpringAIDemo
spring.threads.virtual.enabled=true
server.port=9001
server.servlet.context-path=/ollama
spring.ai.chat.client=ollama
spring.ai.mistral.enabled=false
spring.ai.ollama.chat.options.model=llama2
spring.ai.ollama.embedding.options.model=mxbai-embed-large
spring.ai.ollama.base-url=http://localhost:11434
